{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import wget\n",
    "import os, struct\n",
    "import numpy as np\n",
    "import gzip\n",
    "import sklearn\n",
    "import sklearn.decomposition\n",
    "import array\n",
    "\n",
    "from collections import namedtuple\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_data(directory='./data/'):\n",
    "    \"\"\"Download MNIST database\"\"\"\n",
    "\n",
    "    if os.path.exists(directory):\n",
    "        return\n",
    "\n",
    "    os.makedirs(directory)\n",
    "    wget.download(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", directory, bar=None)\n",
    "    wget.download(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", directory, bar=None)\n",
    "    wget.download(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", directory, bar=None)\n",
    "    wget.download(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\", directory, bar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_mnist(dataset=\"training\", digits=np.arange(10), path=\"./data/\"):\n",
    "    \"\"\"Loads MNIST files into 3D numpy arrays\n",
    "\n",
    "    Adapted from: http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte.gz')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte.gz')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte.gz')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte.gz')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = gzip.open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = array.array(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = gzip.open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = array.array(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [k for k in range(size) if lbl[k] in digits]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = np.zeros((N, rows, cols), dtype=np.uint8)\n",
    "    labels = np.zeros((N, 1), dtype=np.int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = np.array(img[ind[i] * rows * cols: (ind[i] + 1) * rows * cols]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    \"\"\"Preprocess and return training and testing datasets\"\"\"\n",
    "\n",
    "    images = namedtuple('MNIST_images', ['train', 'test'])\n",
    "    labels = namedtuple('MNIST_labels', ['train', 'test'])\n",
    "    images.train, labels.train = load_mnist('training')\n",
    "    images.test, labels.test = load_mnist('testing')\n",
    "\n",
    "    images.train = images.train.reshape(images.train.shape[0], -1)\n",
    "    images.test = images.test.reshape(images.test.shape[0], -1)\n",
    "\n",
    "    images.train = sklearn.preprocessing.normalize(images.train.astype(np.float), axis=1)\n",
    "    images.test = sklearn.preprocessing.normalize(images.test.astype(np.float), axis=1)\n",
    "\n",
    "    labels.train = labels.train.ravel()\n",
    "    labels.test = labels.test.ravel()\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images, labels = split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_splits(splits):\n",
    "    return [split[::-1] for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Kfold'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-18b3c073dc84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mstacking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStacking\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Mike\\Desktop\\New folder\\stacking\\trunk\\stacking.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKfold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Kfold'"
     ]
    }
   ],
   "source": [
    "from stacking import Classifier, Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_SVM_fitter(C=1., kernel='linear', degree=3, gamma=1.):\n",
    "    return lambda X, y: Classifier(SVC(C=C, kernel=kernel, degree=degree, gamma=gamma).fit(X, y).predict)\n",
    "\n",
    "def SVM_fitter(X, y):\n",
    "    classifier = SVC(kernel=kernel, degree=degree, gamma=gamma).fit(X, y)\n",
    "    return Classifier(classifier.predict)\n",
    "\n",
    "def logit_fitter(X, y):\n",
    "    classifier = LogisticRegression('l2', False).fit(X, y)\n",
    "    return Classifier(classifier.predict)\n",
    "\n",
    "def random_forest_fitter(X, y):\n",
    "    classifier = RandomForestClassifier().fit(X, y)\n",
    "    return Classifier(classifier.predict)\n",
    "\n",
    "def random_forest_proba_fitter(X, y):\n",
    "    classifier = RandomForestClassifier().fit(X, y)\n",
    "    return Classifier(classifier.predict_proba)\n",
    "\n",
    "def extra_trees_fitter(X, y):\n",
    "    classifier = ExtraTreesClassifier().fit(X, y)\n",
    "    return Classifier(classifier.predict)\n",
    "\n",
    "def extra_trees_proba_fitter(X, y):\n",
    "    classifier = ExtraTreesClassifier().fit(X, y)\n",
    "    return Classifier(classifier.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(50).fit(images.train)\n",
    "pca_images_train = pca.transform(images.train)\n",
    "pca_images_test = pca.transform(images.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = namedtuple('models', ['logit', 'svm', 'random_forest', 'extra_trees'])\n",
    "predictions = namedtuple('predictions', ['logit', 'svm', 'random_forest', 'extra_trees'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models.logit = LogisticRegression('l2', False).fit(pca_images_train, labels.train)\n",
    "predictions.logit = models.logit.predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.098100000000000007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions.logit != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models.svm = SVC(kernel = 'linear').fit(pca_images_train, labels.train)\n",
    "predictions.svm = models.svm.predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062399999999999997"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions.svm != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models.random_forest = RandomForestClassifier().fit(pca_images_train, labels.train)\n",
    "predictions.random_forest = models.random_forest.predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.069000000000000006"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions.random_forest != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models.extra_trees = ExtraTreesClassifier().fit(pca_images_train, labels.train)\n",
    "predictions.extra_trees = models.extra_trees.predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.071999999999999995"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions.extra_trees != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit_svm = Stacking(base_fitter=logit_fitter, meta_fitter=get_SVM_fitter(C=5, kernel='poly', degree = 2), \n",
    "                     split=lambda I: list(KFold(n=I.size, n_folds=5, shuffle=True)))\n",
    "logit_svm_predictions = logit_svm.fit(pca_images_train, labels.train).predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42509999999999998"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(logit_svm_predictions != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression + Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_rf = Stacking(base_fitter=logit_fitter, meta_fitter=random_forest_fitter, \n",
    "                    split=lambda I: list(KFold(n=I.size, n_folds=5, shuffle=True)))\n",
    "logit_rf_predictions = logit_rf.fit(pca_images_train, labels.train).predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0746"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(logit_rf_predictions != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra trees + Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_logit = Stacking(base_fitter=extra_trees_proba_fitter, meta_fitter=logit_fitter, \n",
    "                    split=lambda I: list(KFold(n=I.size, n_folds=5, shuffle=True)))\n",
    "et_logit_predictions = et_logit.fit(pca_images_train, labels.train).predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47089999999999999"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(et_logit_predictions != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_svm = Stacking(base_fitter=get_SVM_fitter(), meta_fitter=get_SVM_fitter(C=5, kernel='poly', degree = 2), \n",
    "                   split=lambda I: list(KFold(n=I.size, n_folds=5, shuffle=True)))\n",
    "svm_svm_predictions = svm_svm.fit(pca_images_train, labels.train).predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038399999999999997"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(svm_svm_predictions != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_svm = Stacking(base_fitter=random_forest_fitter, meta_fitter=get_SVM_fitter(C=10, kernel='poly', degree = 2), \n",
    "                  split=lambda I: list(KFold(n=I.size, n_folds=5, shuffle=True)))\n",
    "rf_svm_predictions = rf_svm.fit(pca_images_train, labels.train).predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0339"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rf_svm_predictions != labels.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra trees + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wildfowl = Stacking(base_fitter=extra_trees_proba_fitter, meta_fitter=get_SVM_fitter(C=5, kernel='poly', degree = 2), \n",
    "                    split=lambda I: list(KFold(n=I.size, n_folds=5, shuffle=True)))\n",
    "wildfowl_predictions = wildfowl.fit(pca_images_train, labels.train).predict(pca_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024199999999999999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wildfowl_predictions != labels.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0237\n",
      "0.0215\n",
      "0.0249\n",
      "0.0269\n",
      "0.0275\n",
      "0.0282\n"
     ]
    }
   ],
   "source": [
    "for n_folds in [2, 3, 5, 10, 15, 20]:   \n",
    "    et_logit = Stacking(base_fitter=extra_trees_proba_fitter, meta_fitter=get_SVM_fitter(C=5, kernel='poly', degree = 2), \n",
    "                        split=lambda I: list(KFold(n=I.size, n_folds=n_folds, shuffle=True)))\n",
    "    et_logit_predictions = et_logit.fit(pca_images_train, labels.train).predict(pca_images_test)\n",
    "    print(np.mean(et_logit_predictions != labels.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68210000000000004"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stacking import MultiStacking\n",
    "\n",
    "multi_wildfowl = MultiStacking(\n",
    "    fitters=[\n",
    "        random_forest_fitter,\n",
    "        extra_trees_fitter,\n",
    "        get_SVM_fitter(C=5, kernel='poly', degree=2)\n",
    "    ]\n",
    ")\n",
    "multi_wildfowl_predictions = multi_wildfowl.fit(pca_images_train[:100], labels.train[:100]).predict(pca_images_test)\n",
    "np.mean(multi_wildfowl_predictions != labels.test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
